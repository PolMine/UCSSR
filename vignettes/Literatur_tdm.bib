{@incollection{BlätteAndreas20187ZVä,
abstract = {„Big Data“ ist in aller Munde. Zeitungen, Zeitschriften und Bücher greifen das Thema auf; es wird viel debattiert. Wie fundamental die Umwälzungen sind, die mit der Datenflut einhergehen, dringt erst seit kurzem ins öffentliche Bewusstsein. Was aber bedeutet „Big Data“ für die Politikwissenschaft? Welche Herausforderungen stellen sich?
Der Sammelband trägt politikwissenschaftliche Perspektiven auf neue Entwicklungen zusammen, um zur Diskussion darüber beizutragen, welche Art von Veränderungen der Arbeitsweisen, Erkenntnismöglichkeiten und Erkenntnisprozesse empirischer politikwissenschaftlicher Forschung sich aufgrund der Möglichkeiten der Digitalisierung ergeben haben. Der Ausrichtung der Sektion Methoden folgend ist der Band vorrangig auf die methodisch-technischen, weniger auf die moralischen und gesellschaftspolitischen Dimensionen des Gesamtthemas Big Data und New Analytics ausgerichtet.
Mit Beiträgen von
Florian Bader, Joachim Behnke, Andreas Blätte, Sebastian Dumm, Mennatallah El-Assady, Thorsten Faas, Valentin Gold, Simon Hegelich, Christian Hoops, Pascal Jürgens, Andreas Jungherr, Cathleen Kantner, Kelly Lancaster, Christian Müller, Simon Munzert, Dominic Nyhuis, Maximilian Overbeck, Christian Rohrdantz, Christian Rubba, Gary S. Schaal, Kai-Uwe Schnapp, Susanne Schnorr-Bäcker, Harald Schoen, Andree Thieltges und Claudius Wagemann.},
author = {Blätte, Andreas},
booktitle = {Computational Social Science},
edition = {1},
isbn = {9783848743933},
language = {eng ; ger},
pages = {139-162},
publisher = {Nomos Verlagsgesellschaft mbH & Co. KG},
title = {7 Zum Verwechseln ähnlich? Eine Klassifikationsanalyse par-lamentarischen Diskursverhaltens auf Basis des PolMine-Plenarprotokollkorpus},
year = {2018},
}

@Misc{DummTopicModelle,
author = {Dumm, Sebastian},
title = {Topic Modelle, Text Mining Verfahren, Serie "Atomenergiediskurs", Modul 2/5}, 
year = {2014}, 
howpublished = "http://www.epol-projekt.de/wp-content/uploads/2014/10/eTMV_3.pdf"}, 
}

@article{GülzauFabian2020Apsi,
abstract = {This article explores the newspaper discourse surrounding a paradigm shift in social policy. The case at hand, Germany, is a prime example of a welfare state that was particularly resistant to reform. Hence, the rapid paradigm shift in German family policy since the late 1990s is puzzling. This study seeks to resolve this puzzle by drawing on the insight that public discourse is crucial for policy change. Politicians have to promote reforms prior to their implementation. The main channel for communication with the wider public is the mass media. I use newspaper coverage from 1990 to 2016 to analyze whether the media is responsive to reform initiatives. I use topic modeling, an innovative method from the computational social sciences (CSS), to identify dominant themes and shifts over time in a large corpus of newspaper articles. The analysis shows that public discourse was responsive to the parliamentary debate. The article also clarifies the role of critical events and identifies discursive strategies.},
author = {Gülzau, Fabian},
copyright = {2019 The Authors. European Policy Analysis published by Wiley Periodicals, Inc. on behalf of Policy Studies Organization},
issn = {2380-6567},
journal = {European policy analysis},
language = {eng},
number = {1},
pages = {100-118},
title = {A paradigm shift in German family policy: Applying a topic model to map reform and public discourse, 1990-2016},
volume = {6},
year = {2020},
}

@article{GRÜNDER-FAHRERSABINE2018Tatp,
abstract = {Social media are an emerging new paradigm in interdisciplinary research in crisis informatics. They bring many opportunities as well as challenges to all fields of application and research involved in the project of using social media content for an improved disaster management. Using the Central European flooding 2013 as our case study, we optimize and apply methods from the field of natural language processing and unsupervised machine learning to investigate the thematic and temporal structure of German social media communication. By means of topic model analysis, we will investigate which kind of content was shared on social media during the event. On this basis, we will, furthermore, investigate the development of topics over time and apply temporal clustering techniques to automatically identify different characteristic phases of communication. From the results, we, first, want to reveal properties of social media content and show what potential social media have for improving disaster management in Germany. Second, we will be concerned with the methodological issue of finding and adapting natural language processing methods that are suitable for analysing social media data in order to obtain information relevant for disaster management. With respect to the first, application-oriented focal point, our study reveals high potential of social media content in the factual, organizational and psychological dimension of the disaster and during all stages of the disaster management life cycle. Interestingly, there appear to be systematic differences in thematic profile between the different platforms Facebook and Twitter and between different stages of the event. In context of our methodological investigation, we claim that if topic model analysis is combined with appropriate optimization techniques, it shows high applicability for thematic and temporal social media analysis in disaster management.},
author = {GRÜNDER-FAHRER, SABINE and SCHLAF, ANTJE and WIEDEMANN, GREGOR and HEYER, GERHARD},
address = {Cambridge, UK},
copyright = {Copyright Cambridge University Press 2018},
issn = {1351-3249},
journal = {Natural language engineering},
keywords = {Articles},
language = {eng},
number = {2},
pages = {221-264},
publisher = {Cambridge University Press},
title = {Topics and topical phases in German social media communication during a disaster},
volume = {24},
year = {2018},
}

@article{GreeneDerek2017EtPA,
abstract = {This study analyzes the political agenda of the European Parliament (EP) plenary, how it has evolved over time, and the manner in which Members of the European Parliament (MEPs) have reacted to external and internal stimuli when making plenary speeches. To unveil the plenary agenda and detect latent themes in legislative speeches over time, MEP speech content is analyzed using a new dynamic topic modeling method based on two layers of Non-negative Matrix Factorization (NMF). This method is applied to a new corpus of all English language legislative speeches in the EP plenary from the period 1999 to 2014. Our findings suggest that two-layer NMF is a valuable alternative to existing dynamic topic modeling approaches found in the literature, and can unveil niche topics and associated vocabularies not captured by existing methods. Substantively, our findings suggest that the political agenda of the EP evolves significantly over time and reacts to exogenous events such as EU Treaty referenda and the emergence of the Euro Crisis. MEP contributions to the plenary agenda are also found to be impacted upon by voting behavior and the committee structure of the Parliament.},
author = {Greene, Derek and Cross, James P},
address = {New York, USA},
copyright = {Copyright The Author(s) 2017. Published by Cambridge University Press on behalf of the Society for Political Methodology.},
issn = {1047-1987},
journal = {Political analysis},
keywords = {Articles},
language = {eng},
number = {1},
pages = {77-94},
publisher = {Cambridge University Press},
title = {Exploring the Political Agenda of the European Parliament Using a Dynamic Topic Modeling Approach},
volume = {25},
year = {2017},
}

@article{GrimmerJustin2013TaDT,
copyright = {Copyright © The Author 2013. Published by Oxford University Press on behalf of the Society for Political Methodology},
issn = {1047-1987},
journal = {Political analysis},
keywords = {Content analysis ; Learning styles ; Modeling ; Press releases ; Research methods ; Senators ; Text analytics ; Topic models ; Training},
language = {eng},
abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods—they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
author = {Grimmer, Justin and Stewart, Brandon M},
number = {3},
pages = {267-297},
address = {New York, US},
publisher = {Cambridge University Press},
title = {Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts},
volume = {21},
year = {2013},
}

@incollection{ManderscheidKatharina2019TM,
abstract = {Der Begriff „Text Mining“ bezeichnet ein Bündel von computergestützten und algorithmus-basierten Auswertungsverfahren, mit denen Informationen aus un- oder schwachstrukturierten Textdatenbeständen gewonnen werden (Puchinger 2016: 119). Die Verfahren des Text Mining gewinnen in den letzten Jahren in der empirischen Sozialforschung an Bedeutung, da immer mehr Texte – Bücher (Ernst, Kapitel 81 in diesem Band), Zeitschriften und Zeitungen (Klein, Taddicken, Kapitel 82 und 83 in diesem Band) sowie verschiedene Dokumente (Salheiser, Kapitel 80 in diesem Band), aber auch Social Media-Beiträge (Schünzel/Traue, Schmidt, Nam, Schrape/Siri, Kapitel 71, 72, 74 und 75 in diesem Band) – in digitalisierter Form vorliegen. Während die frühen Anwendungen von Text Mining meist auf die Auszählung von Wortvorkommen beschränkt waren, werden in neueren Arbeiten häufig verschiedene Werkzeuge eingesetzt, die auf die Herausarbeitung von Argumentationsstrukturen und Sinnzusammenhänge zielen; des Weiteren werden zunehmend komplexere Auswertungsstrategien entwickelt (Puchinger 2016: 129f.).},
author = {Manderscheid, Katharina},
address = {Wiesbaden},
booktitle = {Handbuch Methoden der empirischen Sozialforschung},
copyright = {Springer Fachmedien Wiesbaden GmbH, ein Teil von Springer Nature 2019},
isbn = {9783658213077},
language = {ger},
pages = {1103-1116},
publisher = {Springer Fachmedien Wiesbaden},
title = {Text Mining},
year = {2019},
}

@article{DennyMatthewJ2018TPFU,
abstract = {Despite the popularity of unsupervised techniques for political science text-as-data research, the importance and implications of preprocessing decisions in this domain have received scant systematic attention. Yet, as we show, such decisions have profound effects on the results of real models for real data. We argue that substantive theory is typically too vague to be of use for feature selection, and that the supervised literature is not necessarily a helpful source of advice. To aid researchers working in unsupervised settings, we introduce a statistical procedure and software that examines the sensitivity of findings under alternate preprocessing regimes. This approach complements a researcher's substantive understanding of a problem by providing a characterization of the variability changes in preprocessing choices may induce when analyzing a particular dataset. In making scholars aware of the degree to which their results are likely to be sensitive to their preprocessing decisions, it aids replication efforts.},
author = {Denny, Matthew J and Spirling, Arthur},
address = {New York, USA},
copyright = {Copyright The Author(s) 2018. Published by Cambridge University Press on behalf of the Society for Political Methodology.},
issn = {1047-1987},
journal = {Political analysis},
keywords = {Articles},
language = {eng},
number = {2},
pages = {168-189},
publisher = {Cambridge University Press},
title = {Text Preprocessing For Unsupervised Learning: Why It Matters, When It Misleads, And What To Do About It},
volume = {26},
year = {2018},
}

@article{ProkschSven-Oliver2009HtAP,
abstract = {The statistical analysis of political texts has received a prominent place in the study of party politics, coalition formation and legislative decision making in Germany. Yet we still lack a thorough understanding of the conditions under which such analysis produces valid estimates of policy positions. This article examines the properties of the word scaling method 'Wordfish' and uses the technique to estimate party positions in Germany. Through Monte Carlo simulations, we investigate the effects of the choice of texts on party position estimates, including the number of documents included in the analysis and their length. Moreover, we present guidelines on how to process linguistic information for political scientists interested in using the technique, focusing specifically on German texts. Finally, we present an analysis of the German party system from 1969-2005 using the Wordfish algorithm. We demonstrate the robustness of the algorithm to extract left-right positions for various subsets of words, but show that agenda effects dominate when estimating a long-time series if the entire manifesto corpus is analysed.},
author = {Proksch, Sven-Oliver and Slapin, Jonathan B},
copyright = {Copyright Association for the Study of German Politics 2009},
issn = {0964-4008},
journal = {German politics},
language = {eng},
number = {3},
pages = {323-344},
publisher = {Routledge},
title = {How to Avoid Pitfalls in Statistical Analysis of Political Texts: The Case of Germany},
volume = {18},
year = {2009},
}

@incollection{ProkschSven-Oliver2020CT,
abstract = {Texte stellen eine der bedeutsamsten Datenquellen in der Politikwissenschaft dar. Mit der computergestützten Textanalyse steht Politikwissenschaftlern ein immer mächtigeres Werkzeug zur Verfügung, um alte und neue Fragen aus verschiedenen Subdisziplinen der Politikwissenschaft zu beantworten. Diese Methoden werden konstant weiterentwickelt und verfeinert, während gleichzeitig immer mehr Textdaten auch elektronisch zur Verfügung stehen. Der vorliegende Beitrag beschreibt die Annahmen und grundsätzlichen Vorgehensweisen und bietet einen Überblick über die wichtigsten computergestützten Textanalyseverfahren von der wörterbuchbasierten Analyse bis hin zu Textskalierung, Textklassifikation und Topic Models. Zudem wird auf geeignete Software verwiesen. Anschließend werden vier politikwissenschaftliche Anwendungsbereiche vorgestellt und mehrere methodische Herausforderungen diskutiert.},
author = {Proksch, Sven-Oliver},
address = {Wiesbaden},
booktitle = {Handbuch Methoden der Politikwissenschaft},
copyright = {Springer Fachmedien Wiesbaden GmbH, ein Teil von Springer Nature 2020},
isbn = {9783658169350},
keywords = {Automatisierte Textanalyse ; Maschinelles Lernen ; Politische Positionen ; Textskalierung ; Topic-Modelle},
language = {ger},
pages = {817-835},
publisher = {Springer Fachmedien Wiesbaden},
title = {Computergestützte Textanalysen},
year = {2020},
}
}